{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreerag-ibtl/tutorial/blob/master/image_ocr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "TF0Q-4j96are",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mkdir '/content/data' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4uXAJwUfy3rf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm -rf ann ann.zip img img.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z5f_l3024lvi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install imgaug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sSnHeM1yGVY1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_YFZnV496j20",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "POEGqu087X60",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zipobject=zipfile.ZipFile('/content/data/img.zip')\n",
        "zipobject.extractall() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pOxZYfLX7aVE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N7tuXP967tV6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zipobject=zipfile.ZipFile('/content/data/ann.zip')\n",
        "zipobject.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZMoVJ0MX7x5b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "print('Keras version', keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KsCHdyh98HhN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import join\n",
        "import json\n",
        "import random\n",
        "import itertools\n",
        "import re\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pylab\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from keras import backend as K\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Input, Dense, Activation\n",
        "from keras.layers import Reshape, Lambda\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing import image\n",
        "import keras.callbacks\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gwWsmXtg8MpB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess=tf.Session()\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXb9luW08PLy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def get_counter(dirpath,tag):\n",
        "    dirname=os.path.basename(dirpath)\n",
        "    ann_dirpath=join(dirpath,'ann')\n",
        "    letters=''\n",
        "    lens=[]\n",
        "    for filename in os.listdir(ann_dirpath):\n",
        "        json_filepath=join(ann_dirpath, filename)\n",
        "        ann=json.load(open(json_filepath, 'r'))\n",
        "        tags=ann['tag']\n",
        "        if tag in tags:\n",
        "            description=ann['description']\n",
        "            lens.append(len(description))\n",
        "            letters+=description\n",
        "    print('Max plate length in \"%s\":'%dirname,max(Counter(lens).keys()))\n",
        "    return Counter(letters)\n",
        "c_val=get_counter('/content/data','val')\n",
        "c_train=get_counter('/content/data','train')\n",
        "letters_train=set(c_train.keys())\n",
        "letters_val=set(c_val.keys())\n",
        "if letters_train == letters_val:\n",
        "    print('Letters in train and val do match')\n",
        "else:\n",
        "    raise Exception()\n",
        "print(len(letters_train),len(letters_val),len(letters_val|letters_train))\n",
        "letters=sorted(list(letters_train))\n",
        "print('Letters:',' '.join(letters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HMFG-QaT0Im6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#sometimes(iaa.ContrastNormalization((0.75,1.5))),\n",
        "#sometimes(iaa.AdditiveGaussianNoise(loc=0,scale=(0.0,0.05*255),per_channel=0.5)),\n",
        "#scale={\"x\":(0.8,1.2),\"y\":(0.8,1.2)},\n",
        "#shear=(-8,8)\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes=lambda aug:iaa.Sometimes(0.5,aug)\n",
        "seq=iaa.SomeOf((0,3),[\n",
        "    sometimes(iaa.Crop(px=(0, 16))),\n",
        "    #sometimes(iaa.ContrastNormalization((0.75,1.5))),\n",
        "    #iaa.Fliplr(0.5),\n",
        "    #sometimes(iaa.AdditiveGaussianNoise(loc=0,scale=(0.0,0.05*255),per_channel=0.5)),\n",
        "    sometimes(iaa.GaussianBlur(sigma=(0,3.0))),        \n",
        "    sometimes(iaa.Affine(\n",
        "        rotate=(-25,25),    \n",
        "        scale={\"x\":(0.8,1.2),\"y\":(0.8,1.2)},\n",
        "        #shear=(-8,8)   \n",
        "    ))\n",
        "],random_order=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uum5hUBD93r_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "letters.append('')\n",
        "def labels_to_text(labels):\n",
        "    return ''.join(list(map(lambda x:letters[int(x)],labels)))\n",
        "def text_to_labels(text):\n",
        "    return list(map(lambda x:letters.index(x),text))\n",
        "def is_valid_str(s):\n",
        "    for ch in s:\n",
        "        if not ch in letters:\n",
        "            return False\n",
        "    return True\n",
        "class TextImageGenerator:    \n",
        "    def __init__(self, \n",
        "                 dirpath,\n",
        "                 tag,\n",
        "                 img_w, img_h, \n",
        "                 batch_size, \n",
        "                 downsample_factor,\n",
        "                 max_text_len=11):        \n",
        "        self.img_h=img_h\n",
        "        self.img_w=img_w\n",
        "        self.batch_size=batch_size\n",
        "        self.max_text_len=max_text_len\n",
        "        self.downsample_factor=downsample_factor   \n",
        "        img_dirpath=join(dirpath, 'img')\n",
        "        ann_dirpath=join(dirpath, 'ann')\n",
        "        self.samples=[]\n",
        "        for filename in os.listdir(img_dirpath):\n",
        "            name,ext=os.path.splitext(filename)\n",
        "            if ext in ['.png', '.jpg']:\n",
        "                img_filepath=join(img_dirpath, filename)\n",
        "                json_filepath=join(ann_dirpath,name+'.json')\n",
        "                ann=json.load(open(json_filepath, 'r'))\n",
        "                description=ann['description']\n",
        "                tags=ann['tag']\n",
        "                if tag not in tags:\n",
        "                    continue\n",
        "                if is_valid_str(description):\n",
        "                    self.samples.append([img_filepath,description])        \n",
        "        self.n=len(self.samples)\n",
        "        self.indexes = list(range(self.n))\n",
        "        self.cur_index = 0        \n",
        "    def build_data(self):\n",
        "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
        "        self.texts = []\n",
        "        for i, (img_filepath, text) in enumerate(self.samples):\n",
        "            img = cv2.imread(img_filepath)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
        "            img = img.astype(np.float32)\n",
        "            img /= 255\n",
        "            # width and height are backwards from typical Keras convention\n",
        "            # because width is the time dimension when it gets fed into the RNN\n",
        "            self.imgs[i, :, :] = img\n",
        "            self.texts.append(text)        \n",
        "    def get_output_size(self):\n",
        "        return len(letters) + 1    \n",
        "    def next_sample(self):\n",
        "        self.cur_index += 1\n",
        "        if self.cur_index >= self.n:\n",
        "            self.cur_index = 0\n",
        "            random.shuffle(self.indexes)\n",
        "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]    \n",
        "    def next_batch(self):\n",
        "        while True:\n",
        "            # width and height are backwards from typical Keras convention\n",
        "            # because width is the time dimension when it gets fed into the RNN\n",
        "            if K.image_data_format() == 'channels_first':\n",
        "                X_data = np.ones([self.batch_size, 1, self.img_w, self.img_h])\n",
        "            else:\n",
        "                X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])\n",
        "            Y_data = np.ones([self.batch_size, self.max_text_len])\n",
        "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)\n",
        "            label_length = np.zeros((self.batch_size, 1))\n",
        "            source_str = []                                   \n",
        "            for i in range(self.batch_size):\n",
        "                img, text = self.next_sample()\n",
        "                img = img.T\n",
        "                if K.image_data_format() == 'channels_first':\n",
        "                    img = np.expand_dims(img, 0)\n",
        "                else:\n",
        "                    img = np.expand_dims(img, -1)\n",
        "                X_data[i] = img\n",
        "                lab_data = []\n",
        "                lab_data = text_to_labels(text)\n",
        "                if len(lab_data) < 11:\n",
        "                  for k in range((11-len(lab_data))):\n",
        "                    lab_data.append('36')\n",
        "                Y_data[i] = lab_data\n",
        "                #Y_data[i] = text_to_labels(text)\n",
        "                source_str.append(text)\n",
        "                label_length[i] = len(text)    \n",
        "            images_aug=seq.augment_images(X_data)    \n",
        "            inputs = {\n",
        "                'the_input': images_aug,\n",
        "                'the_labels': Y_data,\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length,\n",
        "                #'source_str': source_str\n",
        "            }\n",
        "            outputs = {'ctc': np.zeros([self.batch_size])}\n",
        "            yield (inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FOQWTZP99-B5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tiger = TextImageGenerator('/content/data', 'train', 128, 64, 8, 4)\n",
        "tiger.build_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LdYF0SVw-Dku",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for inp, out in tiger.next_batch():\n",
        "    print('Text generator output (data which will be fed into the neutral network):')\n",
        "    print('1) the_input (image)')\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        img = inp['the_input'][0, 0, :, :]\n",
        "    else:\n",
        "        img = inp['the_input'][0, :, :, 0]\n",
        "    \n",
        "    plt.imshow(img.T, cmap='gray')\n",
        "    plt.show()\n",
        "    print('2) the_labels (plate number): %s is encoded as %s' % \n",
        "          (labels_to_text(inp['the_labels'][0]), list(map(int, inp['the_labels'][0]))))\n",
        "    print('3) input_length (width of image that is fed to the loss function): %d == %d / 4 - 2' % \n",
        "          (inp['input_length'][0], tiger.img_w))\n",
        "    print('4) label_length (length of plate number): %d' % inp['label_length'][0])\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYgP36Va-JFf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    y_pred = y_pred[:, 2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "def train(img_w, load=False):\n",
        "    img_h = 64\n",
        "    conv_filters = 16\n",
        "    kernel_size = (3,3)\n",
        "    pool_size = 2\n",
        "    time_dense_size = 32\n",
        "    rnn_size = 512\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        input_shape = (1, img_w, img_h)\n",
        "    else:\n",
        "        input_shape = (img_w, img_h, 1)\n",
        "    batch_size = 32\n",
        "    downsample_factor = pool_size ** 2\n",
        "    tiger_train = TextImageGenerator('/content/data', 'train', img_w, img_h, batch_size, downsample_factor)\n",
        "    tiger_train.build_data()\n",
        "    tiger_val = TextImageGenerator('/content/data', 'val', img_w, img_h, batch_size, downsample_factor)\n",
        "    tiger_val.build_data()\n",
        "    act = 'relu'\n",
        "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
        "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
        "                   activation=act, kernel_initializer='he_normal',\n",
        "                   name='conv1')(input_data)\n",
        "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
        "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
        "                   activation=act, kernel_initializer='he_normal',\n",
        "                   name='conv2')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
        "    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
        "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
        "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
        "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
        "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
        "    gru1_merged = add([gru_1, gru_1b])\n",
        "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
        "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
        "    inner = Dense(tiger_train.get_output_size(), kernel_initializer='he_normal',\n",
        "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
        "    y_pred = Activation('softmax', name='softmax')(inner)\n",
        "    model = Model(inputs=input_data, outputs=y_pred).summary()\n",
        "    labels = Input(name='the_labels', shape=[tiger_train.max_text_len], dtype='float32')\n",
        "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "    if load:\n",
        "        model = load_model('./tmp_model.h5', compile=False)\n",
        "    else:\n",
        "        model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
        "    if not load:\n",
        "        model.fit_generator(generator=tiger_train.next_batch(), \n",
        "                            steps_per_epoch=tiger_train.n,\n",
        "                            epochs=1, \n",
        "                            validation_data=tiger_val.next_batch(), \n",
        "                            validation_steps=tiger_val.n)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qt6yLqZf-MgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = train(128, load=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQ6C7SBK0DHP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm weights.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "96VKLebkob2Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights('weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DMUM69mboh7R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_w = 128\n",
        "img_h = 64\n",
        "conv_filters =16\n",
        "kernel_size = (3,3)\n",
        "pool_size = 2\n",
        "time_dense_size = 32\n",
        "rnn_size = 512\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (1, img_w, img_h)\n",
        "else:\n",
        "    input_shape = (img_w, img_h, 1)\n",
        "batch_size = 32\n",
        "downsample_factor = pool_size ** 2\n",
        "tiger_train = TextImageGenerator('/content/data', 'train', img_w, img_h, batch_size, downsample_factor)\n",
        "tiger_train.build_data()\n",
        "tiger_val = TextImageGenerator('/content/data', 'val', img_w, img_h, batch_size, downsample_factor)\n",
        "tiger_val.build_data()\n",
        "act = 'relu'\n",
        "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
        "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
        "               activation=act, kernel_initializer='he_normal',\n",
        "               name='conv1')(input_data)\n",
        "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
        "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
        "               activation=act, kernel_initializer='he_normal',\n",
        "               name='conv2')(inner)\n",
        "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
        "\n",
        "conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
        "inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
        "inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
        "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
        "gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
        "gru1_merged = add([gru_1, gru_1b])\n",
        "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
        "gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
        "inner = Dense(tiger_train.get_output_size(), kernel_initializer='he_normal',\n",
        "              name='dense2')(concatenate([gru_2, gru_2b]))\n",
        "y_pred = Activation('softmax', name='softmax')(inner)\n",
        "Model(inputs=input_data, outputs=y_pred).summary()\n",
        "\n",
        "labels = Input(name='the_labels', shape=[tiger_train.max_text_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "#if load:\n",
        "    #model = load_model('./tmp_model.h5', compile=False)\n",
        "#else:\n",
        "    #model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
        "model.load_weights('/content/data/weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hE4scKxBosrJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1=Model(inputs=input_data,outputs=y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Mxf0PysELu_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(uploaded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9kgBiMMlIrUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model( 'model1_better.h5' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vyCa1C7SseMj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm test1.jpeg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_m_FmiNVow6w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1phqHSYEJxg1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BcT1SZaWJ_Oc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SPFZ8kDXpFcW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image=cv2.imread('test1.jpeg')\n",
        "image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "image=cv2.resize(image,(128, 64))\n",
        "plt.imshow(image)\n",
        "image=image.T\n",
        "image=image.astype(np.float32)\n",
        "image=image/255\n",
        "image=np.expand_dims(image,-1)\n",
        "image=np.expand_dims(image,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s1Y71crxKIv1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "letters = [ '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z' ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6aci5Ys3h3WC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nB_sXv1OpK58",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_batch(out):\n",
        "    ret = []\n",
        "    for j in range(out.shape[0]):\n",
        "        out_best = list(np.argmax(out[j, 2:], 1))\n",
        "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
        "        outstr = ''\n",
        "        for c in out_best:\n",
        "            if c < len(letters):\n",
        "                outstr += letters[c]\n",
        "        ret.append(outstr)\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZwDUZhnpNlv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out=model.predict(image)\n",
        "decode_batch(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDVfPcqu3-GC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.save('/root/data/model1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dTwopKOW4UW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('/root/data/model1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}